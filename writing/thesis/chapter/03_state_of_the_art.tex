\chapter{State-of-the-Art Simulator Analysis}
A comprehensive analysis of the current edge computing simulation landscape is the focus of the following sections.
The analysis provides the foundation for developing a systematic evaluation framework for edge computing simulators and begins by establishing
clear selection criteria for identifying representative simulators from the extensive body of research and development in this domain.
Following a systematic selection process, ten representative edge computing simulators are examined, each offering distinct approaches to modeling edge computing environments.
The chapter proceeds with detailed simulator profiles that introduce their core architectures, capabilities, and intended use cases, providing readers with essential background for understanding their respective strengths and limitations.
To support the systematic comparison of the ten representative simulators, we establish an analysis framework that defines the aspects and categories in which the comparison should take place.
Subsequently, a structured comparative analysis examines these simulators in comparison to their competitors, revealing significant patterns and variations within the simulation landscape.
These significant key aspects are highlighted, and missing aspects are covered in a comprehensive gap analysis, establishing the foundation for the requirements catalogue developed in the subsequent chapter.

% ------------------------------------------
\section{Selection Criteria and Methodology}
As the edge computing simulation landscape is vast, comparing every existing simulator is neither efficient nor sustainable and does not guarantee that meaningful characteristics are highlighted.
Hence, we select a number of representative simulators to represent the current state-of-the-art for the edge computing simulation landscape.

For this, we must determine which criteria a simulator must meet to be chosen, and the number of simulators must be sufficient to provide a comprehensive view of the landscape.

The first and most critical criterion is that every simulator in this list must be published and accessible as an open-source project, so that a meaningful analysis is possible.
If the simulator is not accessible, no insight can be gained nor can the analysis be reproduced or reviewed. 
Additionally, if the simulator is open-source, the approach by which certain features are implemented can be further reviewed and later referenced for one's own implementation.

Secondly, highly cited or well-established simulators should be present in the list of representatives, as a high citation and reference count demonstrates that the simulators have significant impact in research and development.
Furthermore, if a simulator is highly referenced, it can be considered a foundation upon which other researchers and developers have built, and can therefore demonstrate fundamental capabilities that are important for every simulator.

Lastly, we should include simulators that fulfill a meaningful niche or represent a recent trend, as they show the current development direction in the field.
They also demonstrate the recent adoption of modern technologies in the simulation landscape and provide valuable insight into current challenges faced in edge computing.

Based on these three criteria, we select ten representatives, which we introduce in more detail in the next section.

As a general foundation for our research and analysis, we conduct a literature review of the original paper for each simulator as well as any related papers.
This ensures that we have a general theoretical knowledge base for each simulator, as well as their related components, such as simulators they build upon or reference.
Additionally, we examine the official implementation and documentation to gain broader insight into each feature and the architecture of each simulator.
By testing each simulator, we also ensure that each one is still deployable and works as intended, even if it may be older than others.

% ------------------------------------------
\section{Representative Simulator Overview}
In the following each of the ten representatives gets quickly introduced, by stating which criteria they fulfill and by a quick rundown of their capabilities, foci and current development status as well as their strengths and weaknesses.
This section is only to quickly introduce the representatives and a further more detailed rundown is present in the subsequent section as each important capability gets compared.
% ----------------------------------
\subsection{EdgeCloudSim}\label{sec:EdgeCloudSim}
EdgeCloudSim [\cite{sim-edgecloudsim}] is a highly cited and widely adapted edge computing simulator, which focuses on Mobile Edge Computing (MEC) via cloudlets and general edge computing simulation.
With it being first published August 2018, it is one of the older simulators in this list. As of this thesis, EdgeCloudSim was last updated October 2020.

EdgeCloudSim is based on CloudSim [\cite{sim-base-cloudsim}] and presents a modular architecture with advanced mobility modelling in Java.
The general design philospohy is to create a CloudSim-based framework designed for Edge Computing scenarios with focus on both computational and networking resources.
It supports cloud-edge mobile multi-tier topologies and different network types like WLAN, WAN and cellular networks.

EdgeCloudSim is especially designed for MEC scenarios and shows excellent mobility modeling capabilities.
Additionally to that, the mobility modeling gets supported by a realistic network modeling for WLAN and WAN with distance-based latency and due to its modular architecture, EdgeCloudSim allows easy customization.
Sadly, the development halted as of October 2020 and due to it being focused on MEC scenarios the remaining scope is relatively limited.
It is therefore less suitable for pure IoT or cloud computing scenarios and shows limited built-in support for modern artificial intelligence / machine learning workloads.
Furthermore, it is only single-threaded, which leads to scalability limitations, and has no security, privacy or energy modeling.

% ----------------------------------
\subsection{iFogSim2}\label{sec:iFogSim2}
iFogSim2 [\cite{sim-ifogsim2}] is another highly cited and widely adapted edge computing simulator, which builds upon its previous version iFogSim [\cite{sim-base-ifogsim1}].
It is, just like EdgeCloudSim, based on CloudSim [\cite{sim-base-cloudsim}] and focuses also on MEC scenarios but extends its scope to IoT, fog computing and microservices.
iFogSim2 is developed as a CloudSim-based framework designed for comprehensive Edge/Fog computing scenarios with focus on mobility, clustering and microservice orchestration, and was first published in September 2021.
The development seems to be relatively inactive, as the last meaningful update was done August 2021.

Just as its competitor EdgeCloudSim, it shows an advanced mobility support but provides ways to include real datasets for more realistic approaches.
As for topology, iFogSim2 allows for multi-tier cloud-fog-edge-devices and custom topologies with their respective supported network and protocol types.

iFogSim2 presents comprehensive fog/edge computing simulation capabilities and advance mobility support with it being able to integrate real datasets.
It has strong academic backing and is best used in IoT and fog computing research as well as academic prototyping and clustering algorithm development.
But iFogSim2 also has its weaknesses:
The scalability is limited by its single-threaded execution and it shows limited real-time simulation capabilities.
Furthermore, the output is console-only and needs manual implementation for file output.
It has a limited built-in security modeling and energy modeling capabilities and no native containerization support.
Therefore, it performs relatively poorly for real-time system simulation requirements, massive parallel processing scenarios, pure cloud computing simulations or 
scenarios requiring extensive energy modeling.

% ----------------------------------
\subsection{YAFS}\label{sec:YAFS}
Yet Another Fog Simulator (YAFS) [\cite{sim-yafs}] is a highly cited simulator which was first published in July 2019 and last updated June 2022.
Other than iFogSim2 and EdgeCloudSim, YAFS is written in Python 2.7 and extends EdgeSimPy [\cite{sim-base-edgeSimpy}] and focuses on IoT, fog and edge computing as well as resource allocation.
YAFS is designed to be lightweight, robust and highly configurable based on complex network theory with minimal class structure.

It exceeds in being extremly lightweight and being highly configurable and extensible. 
YAFS shows full transparency of simulation data and allows dynamic control of all simulations aspects.
This makes it perfect for research requiring custom algorithms and policies as well as complex network topology analysis and scenarios requiring high customization.

Nonetheless, as YAFS has a relatively inactive development status and is based on a deprecated python version it has some modern flaws.
For example, it has no built-in energy modeling nor security or privacy features.
Just like its competitors, it struggles with being single-threaded and therefore limits its scalability.
With this, YAFS is not ideal for production or commercial environments, large-scale parallel simulations or research that focus on energy or security.

% ----------------------------------
\subsection{EmuFog}\label{sec:EmuFog}
EmuFog [\cite{sim-emufog}] is highly citated, widely adopted and well established extensible emulation framework for large-scale fog computing written in Kotlin and based on MaxiNet\footnote{\url{https://maxinet.github.io/}} [\cite{sim-base-maxinet}] and Mininet\footnote{\url{https://mininet.org/}} [\cite{sim-base-mininet}].
\todo{Is it okay to have a citation and a footnote ? is it too much ? Idk}
First published in October 2017 and updated until September 2020, EmuFog focuses on large-scale fog computing infrastructure emulation while mainly addressing the network emulation.

It provides highly accurate results and supports docker containerization and both synthetic and real-world topologies.
EmuFog has a good scalable architecture and efficient fog node placement algorithms with cost optimizations, making it a sufficient tool for network performance analysis 
in fog environments, application deployment and orchestration testing as well as large-scale fog infrastructure evaluation.

On the other hand, EmuFog has no mobility nor energy modeling and requires high computational resources for large-scale emulation.
Due to that, large projects are expensive and mobile or energy projects or research is not recommended with EmuFog.
Additionally, its overhead is quite high, making it inefficient for quick prototyping and algorithm development.

% ----------------------------------
\subsection{Mockfog 2.0}\label{sec:Mockfog 2.0}
Mockfog 2.0 [\cite{sim-mockfog2}] is a widely adopted and well established tool in the simulation landscape and is a successor of the previous Mockfog (1.0) [\cite{sim-base-mockfog1}].
It is not a simulator like the previous mentioned, but an cloud-based emulator written in Node.js, which focuses on fog and edge computing for real application testing.
The emulator was first published 2021 and the development halted around June 2021.

Mockfog 2.0 presents a real infrastructure emulation in cloud environments to test fog applications under realistic conditions.
It features docker containerization and automated experiment orchestration while maintaining a real cloud-based emulation with runtime network manipulation.

Due to being a emulation, the resulting behavior is realistic and accurate. 
Additionally, it allows for dynamic,realistic and scalable testing scenarios and reduces manual effort.
With this it succeeds in its main goal of real application testing, but also is useful for validation of prototypes, algorithms and performance.
Additionally, it can be used for infrastructure capacity planning and industrial research making it quite adaptable.

Nevertheless, due to having a cloud infrastructure usage it has high cost and a complex setup.
It is not suitable for large-scale theoretical studies and cannot test theoretical algorithms easily.
Additionally, it has limited mobility support making it inefficient for some projects.

% ----------------------------------
\subsection{Fogify}\label{sec:Fogify}
Fogify [\cite{sim-fogify}] is a Python based emulator that focuses on fog/edge computing in a cloud-native container orchestration based network emulation.
It is designed to be realistic, reproducible and to server scalable fog/edge testbeds using containers.
First published in November 2020, Fogify shows a relatively active development with a modern docker and kubernetes based approach for linux networking.

Due to being realistic and reproducible fog/edge testbeds, it shines at testing real applications in such scenarios.
Furthermore, due to its container and kubernetes integration it supports declarative scenario description and therefore being relatively easy to configure and quite modern.

Sadly, it features no built-in energy modeling which makes it insufficient for energy-focused research unless the energy-consumption is instrumented externally.
Large-scale and time-accelerated scenarios also struggle with Fogify, as its hardware-limited scalability stands in the way.

% ----------------------------------
\subsection{iContinuum}\label{sec:iContinuum}
iContinuum [\cite{sim-icontinuum}] joins Fogify as a python based emulator that uses docker containerization and kubernetes to emulate linux networking.
Here, it is also designed to be realistic and reproducible, but other than the previous, focuses on cloud-to-edge, orchestration and reproducibility of large-scale experimentations. 

iContinuum succeeds in its goals by serving realistic and reproducible cloud-to-edge continuum testbeds while maintaining a multi-domain orchestration and declarative scenario description.
It is therefore suitable for orchestration research across the cloud-edge continuum, testing real applications in distributed scenarios and in network-based resource emulation.

However, just like its competitor, it is hardware-limited in its scalability and has no synthetic time like simulators in this field.
Additionally, it has no built-in energy modeling, making it not as suitable for large-scale, time-accelerated or energy-focused simulation.

% ----------------------------------
\subsection{FogNetSim++}\label{sec:FogNetSim++}
FogNetSim++ [\cite{sim-fognetsim++}] is relatively well known and established tool written in C++ and first published October 2018.
It is based on the OMNeT++\footnote{\url{https://omnetpp.org/}} and INET\footnote{\url{https://inet.omnetpp.org/}} Framework and focuses on network-centric fog environemnts with distributed fog systems.
The development halted as of the same month.

FogNetSim++ succeeds in advance network modeling with packet-level precision and with the built on proven OMNeT++ framework it shows extensive networking capabilties.
Furthermore, it present excellent scalabilities for large-scale network simulations and broad selection of debunnging and visualization tools.
Additionally, it also present deterministic and reproducible simulation results.
This supports network performance analysis and protocol development as well as large-scale network simulation with fog nodes and academic research that requires high network simulation accuracy.

However, due to being highly reliant on OMNeT++ and INET, further development and customization of the simulator require expertise and shows a steep learning curve and complex setup.
Adittionally, the documentation is relatively limited and due to the focus primarly laying on networking other components are being neglected.
This makes the simulator relatively inefficient for quick prototyping and real-time system simulation as well as energy- and security-focused studies.

% ----------------------------------
\subsection{FogTorch$\Pi$}\label{sec:FogTorchPi}
FogTorch$\Pi$ [\cite{sim-fogtorchpi}] is a well established probabilistic analysis tool in graph structure application deployment.
Written in Java in May 2017, FogTorch$\Pi$ focuses on fog computing, Quality of Service (QoS) aware deployment optimization as well as IoT application deployment.
With its probabilistic QoS-assurance and resource consumption estimation for eligible deployments of fog application with focus on deployment descision support, it serves a unique focus in the simulation landscape.
No visible development can be observed since January 2019.

It succeeds in clear separation between infrastructure and application modeling as well as cost-aware deployment optimization.
Therefore, it is best used for fog application deployment planning, QoS-aware deployment optimization, cost analysis for fog deployments and general academic research on deployment strategies in the fog computing field.

However, it features no runtime simulation capabilties and the deployment analysis is rather static with no dynamic reconfiguration or adaptation.
Furthermore, no ernergy or security modeling is present and its limited scalability makes it inefficient for energy or security based large-scaled projects.

% ----------------------------------
\subsection{EdgeAISim}\label{sec:EdgeAISim}
EdgeAISim [\cite{sim-edgeAIsim}] is a relatively new simulator, first published in October 2023, and focuses on the growing trend of artificial intelligence on the edge.
It features an extension to EdgeSimPy [\cite{sim-base-edgeSimpy}], which is written in Python, and focuses on resource management and energy optimization for artificial intelligence and machine learning workflows on the edge.

The integration of advanced AI models for intelligent resource management as well as the use of advanced artificial intelligence techniques like multi-armed bandit, Deep Q-Networks (DQN) and GNNs, makes it an 
efficient simulator in regards to scenarios of energy optimization studies, intelligent resource management and task scheduling algorithm development on the edge.

As EdgeAISim is a relatively small extension and has a very strict focus, it lacks in multiple other features that its competitors present.
Due to this, scenarios without artificial intelligence requirements don't reap any benefits from this simulator, as the workflow either hindered by additional workload or is simply 
delegated to EdgeSimPy.

\begin{figure}[H]
  \centering
  \begin{tabularx}{\textwidth}{l | c | c | X }
    \hline
    \textbf{Name} & \textbf{Language} & \textbf{Type} & \textbf{Focus} \\
    \hline\hline
    EdgeCloudSim  & Java & Sim & Mobile Edge Computing, General Edge Computing\\\hline
    iFogSim2      & Java & Sim & IoT, Mobile Edge Computing, Microservices\\\hline
    YAFS          & Python & Sim & IoT, resource allocation, complex networks theory\\\hline
    EmuFog        & Kotlin & Emu & Large-scale fog infrastructure\\\hline
    Mockfog 2.0   & Node.js & Emu & Real application testing, Cloud-based emulation\\\hline
    Fogify        & Python & Emu & Container orchestration, Network emulation\\\hline
    iContinuum    & Python & Emu & Orchestration, Large-scale experimentation\\\hline
    FogNetSim++   & C++ & Sim & Realistic network-centric distributed systems\\\hline
    FogTorch$\Pi$ & Java & Sim & IoT application deployment, QoS-aware deployment optimization\\\hline
    EdgeAISim     & Python & Sim & AI/ML Edge Computing, Resource management, Energy optimization\\\hline
  \end{tabularx}
  \caption{Summary of representatives of the edge computing simulation landscape}
  \label{tab:overview-table-representatives}
\end{figure}
\todo{Do I need to add a footnote or something to describe what "Sim" and "Emu" is in type ?}

% ------------------------------------------
\section{Comparative Analysis}
In the following, we further dive into each aspect of the representatives and find similarities and differences.
To do that, we first introduce our analysis framework, which covers which aspects we observe, what value they bring to the simulation landscape and what the general structure for our comparison is.
After that we start with the comparison, covering each aspect and dive into further insights that come up during the process.
Additionally, we highlight some common patterns and findings as well as mention some gaps due to missing capabilities, limitations and emerging requirements.

% ----------------------------------
\subsection{Analysis Framework}
To systematically compare each representative with different architectures, foci and implementation approaches, we establish a foundation in form of a framework.
Given that our selected representatives range from simulators to emulators with varying specialized purposes, direct feature-to-feature comparison would be insufficient.
Instead, our framework considers both the specific goals of each representative and the influence of it in the edge computing simulation landscape.
A feature of a fog-edge emulator, may not be a great fit for a cloud-edge simulator, but still can have some insights and useful information regarding implementation or general design.

The framework encompasses six core dimensions that collectively address the complete software lifecycle from development, through deployment to its usage and assessment.
This holistic approach ensures our analysis captures not only what they can do, but also how well it serves researches and users across diverse edge computing scenarios.

\subsubsection{Architectural Dimensions}
The architectural foundation determines the flexibility, maintainability and ability to accurately represent edge computing environments.
It concerns itself with the design choices during the development of the simulator.
This can include the choice of the coverage scope, simulation paradigm, the general design philosophy, architecture patterns and integrations capabilities.

Which layer the simulator covers, is important to understand its purpose and capabilities. 
The coverage scope not only determines requirements for protocols and other features, but also different use cases and therefore the general focus.
It further can determine required modeling complexity, affects scalability requirements and shapes varied approaches during development and usage.
Furthermore, some capabilities, requirements and approaches can be essential for a layer in general.

The choice of the simulation paradigm ,on the other hand, determines whether simulators employ discrete-event simulation for network dynamics, 
continuous-time modeling for resource consumption, agent-based approaches for autonomous behavior or hybrid combinations that leverage multiple paradigms simultaneously.
As all these different paradigms, can have influence over simulation accuracy, time and resource usage, the selection should be not made hastely.

Hence, the general design philosophy is a criticial point, as it can not only determine the simulation paradigm but also can directly influence the focus of the simulator.
As we established, different foci doesn't mean that no insight can be gained for ther simulators. This is also true for the design philosphy.

Additionally, the choice of a modular or monoltihc architecture pattern, is a foundational choice, as modular designs are known to be more maintainable by separating concerns into independent components, and 
monolithc implementations are deemed to be compacter by integrating all functionality within unified frameworks.

\subsubsection{Functional Capabilities}
Functional capabilities encompass the breadth and depth of the edge computing scenarios each simulator can represent.
This does include general functionalities as well as focus-based capabilities, which needs to be weighted.

The general functionalities encompasses for example network modeling, device and infrastructure modeling and application and worload modeling as well as fault tolerance and reliability modeling and security and privacy concerns.
Each of these functionalities can vary in implementation and approach based on multiple factors, just like if simulation or emulation is presented.

Network modeling assesses support for supported topologies, diverse network types, protocol implementations and realistic network conditions including variable delays, bandwidth constraint and congestion-aware behavior.
Additionally, simulated topologies and other feature can have impact in the network modeling as well, making it a core point in the simulator of choice.

Device and infrastructure modeling examines the range of supported device types from resource-constrained sensors to powerful edge servers, including resource modeling, heterogeneity support for diverse device capabilities and realistic scaling bahavior that reflects hardware constraints and performance characteristics.
The degree in which these device needs to be models are in correlation of the level of detail the simulator wants to accomplished and the focus.

Application and workload modeling investigates support for different application architectures, task dependency patterns, data generation and data flow models.
This includes evaluation of service migration capabilities, workload generation methods and QoS requirement modeling for latency, throughput and reliability constraints.

This gets extended by modeling fault tolerance and checking for reliability of the simulated devices and networks.
If the network modeling concerns itself with the aspects of variable delays, fault tolerance concerns itself with the case of failing nodes and devices that would maybe cause these delays.
By modeling fault tolerance, the simulator can check if the scenario is reliable in cases where devices disconnect. 

Furthermore, security and privacy of the simulator as well as the application are important for personal use as well as developing security-aware applications.
These points can be further extended by focus-based capabilities, as every type of focus can have qualifing capabilities for the edge computing landscape.
For example, if the focus lies on mobile devices, mobility modeling is necessary to model different delay and different data generation based on movement and distance to other nodes.
Energy consumption and sustainability can also be capabilities important for the simulator that need to be observed and weighted based on their respective influence in the edge computing simulation landscape.

\subsubsection{Performance and Scalability}
Performance characteristics directly impact practical utility for large-scale edge computing studies.
A simulator that can't be scaled or performs badly in realistic deployment requirements, can be deemed insufficient.
As scalability is a core aspect of the edge, it is a critical aspect that needs to be analysed for each simulation.

Computational efficiency measures simulation execution speed relative to scenario complexity, memory usage patterns and effectiveness of optimization features including caching, checkpointing and incremental simulation capabilities.

Scalability limits determine practical boundaries for scenario complexity, including maximum supportable network nodes, concurrent applications and realistic scenario sizes before performance degrades unacceptably.
This assessment examines parallelization support through multi-threading, distributed processing or GPU acceleration and evaluates how performance scales with increasing scenario complexity.

Resource requirements document hardware dependencies, platform support across operating systems and scaling relationships between simulation complexity and computational demands.
The evaluation includes assessment of memory efficiency, CPU utilization patterns and any spezialized hardware requirements that might limit accessibility or deployment flexibility.

\subsubsection{Usability}
Usability factors significantly influence simulator adoption and research productivity.

An evaluation of the setup and deployment procress asseses installation complexity, dependency management and documentation quality as well as community support avalability.
This includes examination of platform compatibility, deployment options and the overall barrier to entry for new users.

Programming interface analysis compares configuration methods from graphical interfaces to prorgammic APIs, evaluating the balance btween ease of use and flexibility.
The assessment considers API design quality, example scenario availability and the steepness of the learning curve required for productive use across different users expertise levels.
This does not only include the pure usage of said simulator but also the further development.
Furthermore, it also observes the strictness of the simulator, as a simulator which can only be used for one specific scenario may not be suited in general.

Research workflow integration examines support for experimental design including scenario management, parameter sweep capabilities, reproducibility mechanisms through seed control and deterministic execution and statistical analysis features.
Effective simulators should provide data export capabilities, visualization support and integration with external analysis tools to support rigourous experimental methodologies and interpretation of the results in general.

\subsubsection{Extensibility and Customization}
Extensibility determines a simulator's ability to evolve with changing research needs and support novel edge computing concepts.
This ensures that the simulator grows with the changing simulation landscape, adapt modern approaches and can be customized for a variety of scenarios and use cases.
Hence, this aspect is highly dependent on other factors such as the architecture pattern but can also be achieved and influenced by other internal as well as external features.

Plugin architecture is a common way of adding new functionality without modifiying core code.
To assess this architecture, the availability of well-defined extension points, plugin management systems and the ease of integrationg custom components need to observed.

Programming extensibility evaluates API completeness and choice of programming language for custom development, scripting support for automation and the flexibility of extending exisiting models or creating entirely new behavioral representations.
This includes assessment of inheritance mechanisms, interface design and the complexity required for implementing custom device types, protocols or application models.

Data and metric extensibility investigates capabilities for custom metric definitions, support for novel data patterns, integration with real-world datasets and mechanisms for extending output analysis capabilities.
Robust extensibility should enable researchers to adapt simulators for emerging edge computing paradigms without requiring dfundamental architectural chanegs.

\subsubsection{Validation and Evaluation}
Validation capabilities ensure simulation credibility and enable meaningful research conclusion.
The accuracy of the simulators results is important, as inaccurate results defeat the whole purpose of the process as a whole.

Accuracy and validation asssesment examines built-in verification methods, calibration requirements against real-world data and documented accuracy claims with associated error bounds or precision levelvs.

Benchmarking and comparison evlauates availability of standard benchmark scenarios, reference implementationsfor comparative analysis and built-in metrics that enable fair evlauation across different approaches.
The assessment considers whether simulators provide validated baseline scenarios and support for reproductin published research results for comparison, review and transparency of the results.

Metrics and analysis support examines the comprehensivesness of built-in measurement capabilities, configurability of ourput generation and support of custom metric definition.
Effective evaluation support should, as mentioned in previous aspects, include statiscal analysis features, data export capabilities in standard formats and visualization tools that facilitate both real-time monitoring and post processing analysis of simulation results. 

% ----------------------------------
\subsection{Analysis \& Results}
\todo{Missing introduction! (Do i really need one here ?)}

\subsubsection{Architectural Dimensions Comparison}
Starting with the architectural dimensions, the representives demonstrate some architectural diversity and some unity in their approach to edge computing simulation.

\begin{figure}[H]
  \centering
  \begin{tabularx}{\textwidth}{ l | l | l | l }
    \hline
    \textbf{Name} & \textbf{Coverage Scope} & \textbf{Sim. Paradigm} & \textbf{Arch. Pattern} \\
    \hline\hline
    EdgeCloudSim  & Cloud-Edge-Mobile     & DES       & Modular\\\hline
    iFogSim2      & Cloud-Fog-Edge-Device & DES       & Modular\\\hline
    YAFS          & Cloud-Fog-Edge        & DES       & Modular\\\hline
    EmuFog        & Fog-Edge              & Emulation & Modular\\\hline
    Mockfog 2.0   & Cloud-Fog-Edge        & Emulation & Modular\\\hline
    Fogify        & Fog-Edge              & Emulation & Modular\\\hline
    iContinuum    & Cloud-Edge            & Emulation & Modular\\\hline
    FogNetSim++   & Fog-Edge              & DES       & Modular\\\hline
    FogTorch$\Pi$ & Cloud-Fog-Edge        & DES       & Modular\\\hline
    EdgeAISim     & Cloud-Fog-Edge        & DES       & Modular\\\hline
  \end{tabularx}
  \caption{Comparison overview for architectural dimensions}
  \label{tab:analysis-architectural-dimensions}
\end{figure}

As we can see in figure \ref{tab:analysis-architectural-dimensions}, all of the selected representatives demonstrate a relatively clear unity in the choice of architectural pattern, as well as 
the choice of simulation paradigm if they are a simulator and not an emulator.

Every simulator and emulator chose the modular architectural pattern, which allows for easier updates, parallel development and better risk management.
Additionally to that, simulators chose the described standard for simulation paradigms Discrete-Event Simulation (DES) as their respective simulation paradigm.
With the combination of these two, identification of bottlenecks, updating components and optimize resource allocation as well as improve performance and workflow can be easily done.

However, the differences occur in the coverage scope.
As all of the simulators and emulators cover the edge, none is a pure edge concerned simulator/emulator but rather use a hybrid approach with at least two layers, if not more.
Especially, the full-stack of cloud, fog and edge is mostly presented, with the combination of fog and edge alone coming second with a relatively good presented foundation.
The only outlier currently present is iContinuum with a scope of cloud and edge, leaving fog out.

As the boarders between each layer blurs in reality, covering multiple layer does not only make the simulator / emulator more realistic but also supports developers and researchers alike, as not multiple different simulator and emulators need to be intertwined to achieve the goal.
However, the choice of how many layers should be covered, should be considered and studied based on the focus of the simulator / emulator.

Based on the comparison, at least fog and edge should be covered to present not only the devices on the edge but also connectivity. 
The ideal would be the full-stack of cloud, fog and edge to have a complete and modern simulator / emulator that covers all potential applications and projects.

\subsubsection{Functional Capabilities Comparison}
Network modeling capabilities demonstrate significant variation based on each representatives architectural approach and target scenario.

\begin{figure}[H]
  \centering
  \begin{tabularx}{\textwidth}{ l | X | X | X  }
    \hline
    \textbf{Name} & \textbf{Network Types} & \textbf{Supported Protocols} & \textbf{Topology Support}\\
    \hline\hline
    EdgeCloudSim  & WLAN, WAN, Cellular                         & HTTP, Custom                            & Hierarchical \\\hline
    iFogSim2      & WiFi, Ethernet, Cellular, Custom            & TCP/IP, HTTP, MQTT, Custom              & Hierarchical, Custom\\\hline
    YAFS          & Generic/Custom                              & Generic/Custom                          & Any \\\hline
    EmuFog        & WiFi, Ethernet                              & TCP/IP, HTTP, Custom                    & Custom, Real-world datasets\\\hline
    Mockfog 2.0   & Any                                         & Any                                     & Hierarchical, Custom \\\hline
    Fogify        & Ethernet, Wifi, Cellular                    & TCP, HTTP, MQTT                         & Hierarchical, Mesh, Custom \\\hline
    iContinuum    & Ethernet, Wifi, Cellular                    & TCP, HTTP, MQTT                         & Hierarchical, Mesh \\\hline
    FogNetSim++   & WiFi, Ethernet, Cellular, WAN, LAN, Custom  & TCP/IP, UDP, HTTP, Custom               & Hierarchical, Mesh, Tree, Custom \\\hline
    FogTorch$\Pi$ & Abstract                                    & Abstract                                & Hierarchical, Custom \\\hline
    EdgeAISim     & Ethernet, WiFi, Cellular                    & TCP/IP, HTTP, MQTT                      & Hierarchical, Custom \\\hline
  \end{tabularx}
  \caption{Comparison overview of network modeling types}
  \label{tab:analysis-network-modeling-types}
\end{figure}

Topologies are often depicted as hierarchical with the most presented addition of custom topologies.
EdgeCloudSim only supports hierarchical topologies and is therefore the most strict simulator in that comparison.
Every other simulator and emulator does specifically support either hierarchical or custom topologies, which includes hierarchical.
In general most of the simulators and emulators include a way to customize and configure topologies, which leads to a customizable scenarios and simulations.
YAFS represents this aspect the most, as its focus on complex network-theory, allows it to freely deploy any topology.
EmuFog, on the other hand, stands out for its integration of custom as well as real-world datasets as topologies. 
It uses the topologie generator BRITE [\cite{BRITE}] for custom topologies and the real-world datasets from CAIDA's Resource Catalog \footnote{\url{https://www.caida.org/}}, which makes it highly customizable and realistic as an emulator.

As a general rule, all simulators and emulators support standardized protocols for their respective network types.
EdgeCloudSim simplifies network modeling to focus on mobile edge specifics, rather than additional abstraction of network and protocol types.
This is realtively also the case for EdgAISim and emulators like EmuFog, Fogify and iContinuum.
As the latter are emulators, their respective emulated network is limited.
The only exception is Mockfog 2.0, as it is highly configurable and support any network type and protocols, with the limitation that the deployed network type and protocols must be supported by the underlying cloud infrastructure.
EdgeAISim is limited in its network capabilities by EdgeSimPy, which, as its based, does not provide extravagant protocols or types.
iFogSim2 provides, on the other hand, a more comprehensive network modeling, as the default supported types are broader and custom network types and protocol types can be achieved.

FogTorch$\Pi$ is an outlier in this regard, as it not really has a direct network modelling but generic network links with configurable QoS profiles.
The same profiles represent the protocols, making FogTorch $\Pi$ not really comparable to its competitors at a whole.

\begin{figure}[H]
  \centering
  \begin{tabularx}{\textwidth}{l | X | X }
    \hline
    \textbf{Name} & \textbf{Bandwidth Modeling} & \textbf{Delay Modeling} \\
    \hline\hline
    EdgeCloudSim  & Congestion-aware, configurable per link & Distance-based, dynamic\\\hline
    iFogSim2      & Variable, configurable per link/node    & Propagation, queueing, processing delays\\\hline
    YAFS          & Configurable, supports dynamic changes  & Configurable, supports dynamic changes\\\hline
    EmuFog        & Realistic                               & Realistic\\\hline
    Mockfog 2.0   & Realistic                               & Realistic\\\hline
    Fogify        & Realistic                               & Realistic or configurable \\\hline
    iContinuum    & Configurable per link                   & Configurable per link \\\hline
    FogNetSim++   & Configurable, packet-level              & Configurable, packet-level\\\hline
    FogTorch$\Pi$ & Probabilistic                           & Probabilistic\\\hline
    EdgeAISim     & Configurable per link                   & Configurable per link\\\hline
  \end{tabularx}
  \caption{Comparison overview of bandwidth and delay modeling approaches}
  \label{tab:analysis-network-characteristics}
\end{figure}

Characteristics of said network modeling, show a broader unity as the network modeling itself.
Almost all simulators, provide configurable bandwidth modeling per link or node.

Emulators generally depict a realistic network through emulation, while Mockfog 2.0 has further means for configuration.
EdgeCloudSim has congestion-aware bandwidth modeling and based on the focus on MEC distance based and dynamic delay modeling.
With this combination, it presents a robust and rather realistic approach for network modeling.
iFogSim2 allows for different delay models to be used. 
It supports propagation, queueing and processing delays, therefore presenting a greater selection for different scenarios.
FogTorch$\Pi$, on the other hand, provides probabilistic means for bandwidth and delay modeling.
It is thereby less granualar in detail, as it may not capture fine-grained, event level interactions like packet collisions and protocol specific behaviors.
This makes it limited in realism for protocol and network studies.
Additionally it is rather static and validation may be challenging, as results dependent on well-calbrated to real-world data.
However, probabilistic modeling allows to represent real-world variability if calibrated correctly and may catch uncertainty in network conditions like fluctuating bandwidth, random delays and failurs.

Device and infrastructure modeling reveals fundamental differences in abstraction leveles and resource representations.
Emulation platforms in general model real hardware constraints through container resource limits, providing authentic resource contention but with limited abstraction capabilities.
Traditional simulators, like EdgeCloudSim, iFogSim2, and iFogNetSim++, show detailed and heterogeneous device modeling with CPU, memory, storage and energy consumption parameters.
While specialized tools, like FogTorch$\Pi$, focus on ML-specific resource characteristics which includes GPU and inference accelerators.
EdgeAISim is a combination of both aspects, as its base EdgeSimPy shows adaptation of Traditional simulators and the AI/ML based focus of EdgeAISim has some regards for GPU and inference accelerators.
Last but not least, YAFS emphasizes computational flexibility through abstract resource containers, making it highly configurable and abstract.

Thus with the general problem of heterogeneity on the edge, edge computing simulators should provide meaningful ways to model different aspects of devices and their infrastructure
to simulate authentic behavior on the edge.

Application and workload patterns also present similar level of variation as the device and infrastructure modeling.

\begin{figure}[H]
  \centering
  \begin{tabularx}{\textwidth}{ l | X | X | X | X }
    \hline
    \textbf{Name} & \textbf{Application Architecture} & \textbf{Task Dependencies}\\
    \hline\hline
    EdgeCloudSim  & Mobile application patterns, Back- and Foreground task classification & Parent-child relationships \\\hline
    iFogSim2      & Monolithic, Microservice                                              & DAG, Precedence constraints \\\hline
    YAFS          & Flexible computational graphs                                         & Configurable graph-based \\\hline
    EmuFog        & Real Containerized                                                    & Docker container linking \\\hline
    MockFog 2.0   & Container Orchestration, Real microservices                           & Container orchestration \\\hline
    Fogify        & Kubernetes, Pod-based                                                 & Kubernetes service meshes\\\hline
    iContinuum    & Abstract Services, Real containerized applications                    & Cross-service communication \\\hline
    FogNetSim++   & Fog-specific                                                          & DAG \\\hline
    FogTorch$\Pi$ & ML inference containers                                               & ML pipeline chains \\\hline
    EdgeAISim     & Neural networks, Federated learning patterns                          & AI pipeline dependencies \\\hline
    
  \end{tabularx}
  \caption{Comparison overview for application architecture and task dependency}
  \label{tab:analysis-application-arch-task-dep}
\end{figure}
Emulation platforms handle real application architectures through emulation.
While EmuFog, Mockfog 2.0 and Fogify built upon their respective containerized approaches with Docker and Kubernetes for real containerized applications, iContinuum brides simulation and emulation with service-oriented application modeling that can represent both abstract services and real containerized application across the computing continuum.
Based on the approach, the task dependencies are handled either via the containerize technology.
Thus, emulators provide reproducible and robust ways of application and task dependencies by building upon standardized and proofed robust modern technologies.

Traditional simulators on the other hand vary heavily in their approaches.
iFogSim2 and FotNetSim++ build upon Directed-Acyclic Graph (DAG) for Task dependencies, but have different application architectures.
FogTorch$\Pi$ and EdgeAISim have a similar relationship, as both present application architecture suited for ML-tasks with taks dependencies relying on pipelines in their respective fields.

Traditional simulators succeed in abstract application modeling flexibilty and differ more in this domain as emulators that provide authentic application execution.
Specialized tools, like EdgeAISim and FogTorch$\Pi$ provde domain-optimized application support with respective pipeline chains and dependencies, while other simulators built upon their respective target and focus group and use established procedures like Directed-acyclic graphs (DAG) and Parent-Child relationships.

\begin{figure}[H]
  \centering
  \begin{tabularx}{\textwidth}{ l | X | X }
    \hline
    \textbf{Name} & \textbf{Data Generation} & \textbf{Data Flow Models}\\
    \hline\hline
    EdgeCloudSim  & Synthetic               & Mobile data patterns, Location-based \\\hline
    iFogSim2      & Synthetic, Integration  & Periodic, Bursty, IoT streams \\\hline
    YAFS          & Synthetic, Integration  & Stream processing, Batch jobs \\\hline
    EmuFog        & Integration             & Real data processing \\\hline
    MockFog 2.0   & Integration             & Real-world data integration \\\hline
    Fogify        & Integration             & Persistent volumes, Config maps \\\hline
    iContinuum    & Integration             & Real-time data routing \\\hline
    FogNetSim++   & Synthetic               & Data aggregation, Filtering \\\hline
    FogTorch$\Pi$ & Limited Synthetic       & Model I/O, Batch processing \\\hline
    EdgeAISim     & Sinthetic, Integration  & Training data, Inference patterns \\\hline
  \end{tabularx}
  \caption{Comparsion overview for data generation and flow models}
  \label{tab:analysis-data-gen-n-flow}
\end{figure}

Data generation is provided either syntehtic or with real-world dataset integration.
Emulation in general features emulated real-world data, thereby only offering its integration.
Traditional simulators on the other hand, provide always a way for synthetic data to generate.
EdgeCloudSim has specific designed workload and poisson distribution for data generation, while FogNetSim++ focuses on the synthetic traffic via OMNeT++ and the scenario configuration.
Both of these simulator provide no integration of real-world datasets.
iFogSim2, YAFS and EdgeAISim on the other hand provide means to generate data synthetically and to integrate real-world datasets.
Here, iFogSim2 allows XML configuration and trace-based workloads, YAFS allows for customizable distributions, timestamp arrays and support of real traces, while EdgeAISim support AI-driven workload generation and integration of real traces via EdgeSimPy.
An outlier here lies within FogTorch$\Pi$ again, as its focuses more on deployment and is rather an analysis tool, its data generation is very limited for probabilistic deployment analysis and support only limited runtime data generation.

The data flow is modeled based on the focus of each project. 
While emulators target real data processing and persistency, simulators target stream processing and inconsistency in the flow with mobile data patterns and bursty periodic behavior.
Both kinds of flows represent authentic and realistic data behavior, as real world data is also inconsistent.

Fault Tolerance and reliability support are demonstrated by varying sophistication levels across all evaluated tools.
\begin{figure}[H]
  \centering
  \begin{tabularx}{\textwidth}{ l | X | X | X }
    \hline
    \textbf{Name} & \textbf{Failure Types} & \textbf{Detection Methods} & \textbf{Recovery Strategies}\\
    \hline\hline
    EdgeCloudSim  & Mobile device, Network failure  & Timeout                       & Task migration \\\hline
    iFogSim2      & Device, Network failure         & Heartbeat, Timeout            & Basic restart \\\hline
    YAFS          & Configurable failures           & Custom detection              & Configurable recovery \\\hline
    EmuFog        & Container failure               & Docker health checks          & Container restart \\\hline
    MockFog 2.0   & Container/Service failure       & Orchestration monitoring      & Auto-restart, Isolation \\\hline
    Fogify        & Pod/Service failure             & Kubernetes probes, Monitoring & Kubernetes healing, Migration \\\hline
    iContinuum    & Service failure                 & Cross-tier monitoring         & Service migration \\\hline
    FogNetSim++   & Hierarchical failure            & Fog-aware monitoring          & Redundancy, Failover \\\hline
    FogTorch$\Pi$ & Model deployment failure        & Health checks                 & Model redeployment \\\hline
    EdgeAISim     & Model degradation, Byzantine    & AI-aware detection            & Model recovery, Consensus \\\hline
  \end{tabularx}
  \caption{Comparison overview for fault tolerance and reliability support}
  \label{tab:analysis-fault-tolerance}
\end{figure}

As figure \ref{tab:analysis-fault-tolerance} presents, emulators mainly focus on container failures that gets detected by monitoring the system and health checks and get recovered by simply restarting the resource.
Traditional simulators on the other hand show a more device focused appoach by checking the state of the device and application via timeouts, heartbeats and health checks or by monitoring the general network for anomalies.
Recovery is often achieved with task migration to other devices or simple restarts of the original failing devices or applications.

\todo{Quick stuff i just noticed: Maybe change "Name" into "Tool" for all tables ?}

Security and privacy is an aspect that varies drastically across the simulation landscape. 
Not only in implemtation approaches and covered scenarios but also general existance in some tools.
\begin{figure}[H]
  \centering
  \begin{tabularx}{\textwidth}{ l | X | X | X }
    \hline
    \textbf{Name} & \textbf{Security Mechanisms} & \textbf{Privacy Support} & \textbf{Attack Modeling}\\
    \hline\hline
    EdgeCloudSim  & Secure offloading, Transmission encryption & None & None \\\hline
    iFogSim2      & Authentication, Encryption overhead, Trust models & Basic data anonymization & Limited, custom extensions possible \\\hline
    YAFS          & None, custom extension required & None & None, custom extensionr equired  \\\hline
    EmuFog        & None, relies on Docker/Mininet & None & None \\\hline
    MockFog 2.0   & None & None & None \\\hline
    Fogify        & None & None & None \\\hline
    iContinuum    & None & None & None \\\hline
    FogNetSim++   & None, relies on OMNeT++/INET & None & None \\\hline
    FogTorch$\Pi$ & None & None & None \\\hline
    EdgeAISim     & None, can simulate AI-based anomaly detection & None & None  \\\hline
  \end{tabularx}
  \caption{Comparison overview of default security and privacy measures}
  \label{tab:analysis-security-n-privacy}
\end{figure}

Most tools do not present a default security mechanisms, privacy support or attack modeling, and abstract the concerns mostly to the application.
The emulators in particular provide no implementation for testing the security or privacy in containers and rely heavily on the implemented security measure in their respective technologies. 
They depict only attack modeling if its implemented in the application itself.
The traditional simulators provide, with the exception of EdgeCloudSim and iFogSim2, no further implementation of security or privacy measures as well as attack modeling.
YAFS and FogNetSim++, due to their highly customizable nature, show extensions point for said security and privacy concern but at the current state they also dont provide any in the default implementation.
EdgeAISim also provides no default implementation of security and privacy measures, but provides an AI-based anomaly detection simulation, for a way to at least try to detect attacks.

On the other hand, EdgeCloudSim and iFogSim2 provide relatively basic implementations of security mechanisms, that provide more means to simulate cost and overhead of encryptions and no real protocol-level securitym, which makes their implemented security relatively limited and mostly for research prototyping.
 
Mobility support is relatively focus-based capability for tools to have. 
If the focus does not lie on mobile devices, for example in a static deployment, mobility could not be deemed necessary, on the hand multiple projects in the field of edge computing and most presentably in the field of IoT device, show usage of mobile devices and therefore their respective simualtors provide necessary means to simulate the network and data characteristics of mobility.
\begin{figure}[H]
  \centering
  \begin{tabularx}{\textwidth}{ l | X | X | X | X }
    \hline
    \textbf{Name} & \textbf{Mobility Models} & \textbf{Handover Support} & \textbf{Location Services} & \textbf{Dynamic Topology}\\
    \hline\hline
    EdgeCloudSim  & Advance cellular models & Advanced  & Location-based services   & User mobility \\\hline
    iFogSim2      & Basic mobility models   & Limited   & Basic location-awareness  & Node mobility \\\hline
    YAFS          & Limited                 & None      & None                      & Dynamic placement \\\hline
    EmuFog        & None                    & None      & None                      & None \\\hline
    MockFog 2.0   & None                    & None      & None                      & None \\\hline
    Fogify        & None                    & None      & None                      & None \\\hline
    iContinuum    & None                    & None      & None                      & None \\\hline
    FogNetSim++   & Limited                 & None      & None                      & Limited  \\\hline
    FogTorch$\Pi$ & None                    & None      & None                      & None \\\hline
    EdgeAISim     & Limited                 & None      & None                      & Limited \\\hline
  \end{tabularx}
  \caption{Comparison overview of mobility modeling}
  \label{tab:analysis-mobility}
\end{figure}

EdgeCloudSima nd iFogSim2 provide with their focus on mobile and IoT devices, advanced mobility support for simulations on the edge.
Due to their robustness with handovers, location services and dynamic topologies, they provide essential features for mobility focus projects.
YAFS, EdgeAISim and FogNetSim++ provide limited or user-extendable mobility, but are not as advanced on default as their previous mentioned competitors.
EdgeAISim especially provides no further implementation but relies mainly on its base EdgeSimPy in this regard.
However, every other tool, regardless if emulator or simulator, disregards mobility entirely and therefore provides no implementation for such scenarios.

Energy consumption, as well, is a relatively sporadic deployed feature in the edge computing simulation landscape.
\begin{figure}[H]
  \centering
  \begin{tabularx}{\textwidth}{ l | X | X | X }
    \hline
    \textbf{Name} & \textbf{Energy Modeling Scope} & \textbf{Optimization Support} & \textbf{Granularity}\\
    \hline\hline
    EdgeCloudSim  & None                                & None                    & None \\\hline
    iFogSim2      & Basic device-level energy modeling  & Energy-aware placement  & Per device, per task, limited accuracy \\\hline
    YAFS          & None                                & None                    & None \\\hline
    EmuFog        & None                                & None                    & System, per container \\\hline
    MockFog 2.0   & None                                & None                    & System, per container \\\hline
    Fogify        & None                                & None                    & System, per container \\\hline
    iContinuum    & None                                & None                    & System, per container \\\hline
    FogNetSim++   & None                                & None                    & None \\\hline
    FogTorch$\Pi$ & None                                & None                    & None \\\hline
    EdgeAISim     & AI/ML workload energy modeling      & Energy optimization     & Per task, per device \\\hline
  \end{tabularx}
  \caption{Comparison over of energy consumption modeling}
  \label{tab:analysis-energy}
\end{figure}

Figure \ref{tab:analysis-energy} shows, that only iFogSim2 and EdgeAISim provide meaningful implementations for simulation energy consumption for energy concerns scenarios.
However, the emulators do not need to simulate energy consumption, as they emulate a real device and therefore can measure real energy usage externally.
This provides energy consumptions based on total system consumption but also per container or pod and can be extended to per task if instrumented in the application.

Contrary to the belief that if we cover mobile devices, we always look out for battery life and energy consumption, EdgeCloudSim does not provide a meaningful energy consumption model.
It can only be approximated by resource utilization based on scenario results, but no direct energy model is implemented.
However, it is mentioned in the documentation of EdgeCloudSim\footnote{\url{https://github.com/CagataySonmez/EdgeCloudSim}} as a needed feature for the simulator.

\subsubsection{Performance and Scalability Comparison}

\subsubsection{Usability and User Experience Comparsion}

\subsubsection{Extensibility and Customization Comparison}

\subsubsection{Validation and Evaluation Support Comparison}
% ----------------------------------
\subsection{Key Findings \& Gap Analysis}
\todo{Common patterns, performance leaders, comprehensive solutions, specialized tools}
\todo{Missing capabilities, limited coverage area, scalability limitations, validation weaknesses, integration challenges, emerging requirements}