\chapter{State-of-the-Art Simulator Analysis}
A comprehensive analysis of the current edge computing simulation landscape is the focus of the following sections.
The analysis provides the foundation for developing a systematic evaluation framework for edge computing simulators and begins by establishing
clear selection criteria for identifying representative simulators from the extensive body of research and development in this domain.
Following a systematic selection process, ten representative edge computing simulators are examined, each offering distinct approaches to modeling edge computing environments.
The chapter proceeds with detailed simulator profiles that introduce their core architectures, capabilities, and intended use cases, providing readers with essential background for understanding their respective strengths and limitations.
To support the systematic comparison of the ten representative simulators, we establish an analysis framework that defines the aspects and categories in which the comparison should take place.
Subsequently, a structured comparative analysis examines these simulators in comparison to their competitors, revealing significant patterns and variations within the simulation landscape.
These significant key aspects are highlighted, and missing aspects are covered in a comprehensive gap analysis, establishing the foundation for the requirements catalogue developed in the subsequent chapter.

% ------------------------------------------
\section{Selection Criteria and Methodology}
As the edge computing simulation landscape is vast, comparing every existing simulator is neither efficient nor sustainable and does not guarantee that meaningful characteristics are highlighted.
Hence, we select a number of representative simulators to represent the current state-of-the-art for the edge computing simulation landscape.

For this, we must determine which criteria a simulator must meet to be chosen, and the number of simulators must be sufficient to provide a comprehensive view of the landscape.

The first and most critical criterion is that every simulator in this list must be published and accessible as an open-source project, so that a meaningful analysis is possible.
If the simulator is not accessible, no insight can be gained nor can the analysis be reproduced or reviewed. 
Additionally, if the simulator is open-source, the approach by which certain features are implemented can be further reviewed and later referenced for one's own implementation.

Secondly, highly cited or well-established simulators should be present in the list of representatives, as a high citation and reference count demonstrates that the simulators have significant impact in research and development.
Furthermore, if a simulator is highly referenced, it can be considered a foundation upon which other researchers and developers have built, and can therefore demonstrate fundamental capabilities that are important for every simulator.

Lastly, we should include simulators that fulfill a meaningful niche or represent a recent trend, as they show the current development direction in the field.
They also demonstrate the recent adoption of modern technologies in the simulation landscape and provide valuable insight into current challenges faced in edge computing.

Based on these three criteria, we select ten representatives, which we introduce in more detail in the next section.

As a general foundation for our research and analysis, we conduct a literature review of the original paper for each simulator as well as any related papers.
This ensures that we have a general theoretical knowledge base for each simulator, as well as their related components, such as simulators they build upon or reference.
Additionally, we examine the official implementation and documentation to gain broader insight into each feature and the architecture of each simulator.
By testing each simulator, we also ensure that each one is still deployable and works as intended, even if it may be older than others.

% ------------------------------------------
\section{Representative Simulator Overview}
In the following each of the ten representatives gets quickly introduced, by stating which criteria they fulfill and by a quick rundown of their capabilities, foci and current development status as well as their strengths and weaknesses.
This section is only to quickly introduce the representatives and a further more detailed rundown is present in the subsequent section as each important capability gets compared.
% ----------------------------------
\subsection{EdgeCloudSim}\label{sec:EdgeCloudSim}
EdgeCloudSim [\cite{sim-edgecloudsim}] is a highly cited and widely adapted edge computing simulator, which focuses on Mobile Edge Computing (MEC) via cloudlets and general edge computing simulation.
With it being first published August 2018, it is one of the older simulators in this list. As of this thesis, EdgeCloudSim was last updated October 2020.

EdgeCloudSim is based on CloudSim [\cite{sim-base-cloudsim}] and presents a modular architecture with advanced mobility modelling in Java.
The general design philospohy is to create a CloudSim-based framework designed for Edge Computing scenarios with focus on both computational and networking resources.
It supports cloud-edge mobile multi-tier topologies and different network types like WLAN, WAN and cellular networks.

EdgeCloudSim is especially designed for MEC scenarios and shows excellent mobility modeling capabilities.
Additionally to that, the mobility modeling gets supported by a realistic network modeling for WLAN and WAN with distance-based latency and due to its modular architecture, EdgeCloudSim allows easy customization.
Sadly, the development halted as of October 2020 and due to it being focused on MEC scenarios the remaining scope is relatively limited.
It is therefore less suitable for pure IoT or cloud computing scenarios and shows limited built-in support for modern artificial intelligence / machine learning workloads.
Furthermore, it is only single-threaded, which leads to scalability limitations, and has no security, privacy or energy modeling.

% ----------------------------------
\subsection{iFogSim2}\label{sec:iFogSim2}
iFogSim2 [\cite{sim-ifogsim2}] is another highly cited and widely adapted edge computing simulator, which builds upon its previous version iFogSim [\cite{sim-base-ifogsim1}].
It is, just like EdgeCloudSim, based on CloudSim [\cite{sim-base-cloudsim}] and focuses also on MEC scenarios but extends its scope to IoT, fog computing and microservices.
iFogSim2 is developed as a CloudSim-based framework designed for comprehensive Edge/Fog computing scenarios with focus on mobility, clustering and microservice orchestration, and was first published in September 2021.
The development seems to be relatively inactive, as the last meaningful update was done August 2021.

Just as its competitor EdgeCloudSim, it shows an advanced mobility support but provides ways to include real datasets for more realistic approaches.
As for topology, iFogSim2 allows for multi-tier cloud-fog-edge-devices and custom topologies with their respective supported network and protocol types.

iFogSim2 presents comprehensive fog/edge computing simulation capabilities and advance mobility support with it being able to integrate real datasets.
It has strong academic backing and is best used in IoT and fog computing research as well as academic prototyping and clustering algorithm development.
But iFogSim2 also has its weaknesses:
The scalability is limited by its single-threaded execution and it shows limited real-time simulation capabilities.
Furthermore, the output is console-only and needs manual implementation for file output.
It has a limited built-in security modeling and energy modeling capabilities and no native containerization support.
Therefore, it performs relatively poorly for real-time system simulation requirements, massive parallel processing scenarios, pure cloud computing simulations or 
scenarios requiring extensive energy modeling.

% ----------------------------------
\subsection{YAFS}\label{sec:YAFS}
Yet Another Fog Simulator (YAFS) [\cite{sim-yafs}] is a highly cited simulator which was first published in July 2019 and last updated June 2022.
Other than iFogSim2 and EdgeCloudSim, YAFS is written in Python 2.7 and extends EdgeSimPy [\cite{sim-base-edgeSimpy}] and focuses on IoT, fog and edge computing as well as resource allocation.
YAFS is designed to be lightweight, robust and highly configurable based on complex network theory with minimal class structure.

It exceeds in being extremly lightweight and being highly configurable and extensible. 
YAFS shows full transparency of simulation data and allows dynamic control of all simulations aspects.
This makes it perfect for research requiring custom algorithms and policies as well as complex network topology analysis and scenarios requiring high customization.

Nonetheless, as YAFS has a relatively inactive development status and is based on a deprecated python version it has some modern flaws.
For example, it has no built-in energy modeling nor security or privacy features.
Just like its competitors, it struggles with being single-threaded and therefore limits its scalability.
With this, YAFS is not ideal for production or commercial environments, large-scale parallel simulations or research that focus on energy or security.

% ----------------------------------
\subsection{EmuFog}\label{sec:EmuFog}
EmuFog [\cite{sim-emufog}] is highly citated, widely adopted and well established extensible emulation framework for large-scale fog computing written in Kotlin and based on MaxiNet\footnote{\url{https://maxinet.github.io/}} [\cite{sim-base-maxinet}] and Mininet\footnote{\url{https://mininet.org/}} [\cite{sim-base-mininet}].
\todo{Is it okay to have a citation and a footnote ? is it too much ? Idk}
First published in October 2017 and updated until September 2020, EmuFog focuses on large-scale fog computing infrastructure emulation while mainly addressing the network emulation.

It provides highly accurate results and supports docker containerization and both synthetic and real-world topologies.
EmuFog has a good scalable architecture and efficient fog node placement algorithms with cost optimizations, making it a sufficient tool for network performance analysis 
in fog environments, application deployment and orchestration testing as well as large-scale fog infrastructure evaluation.

On the other hand, EmuFog has no mobility nor energy modeling and requires high computational resources for large-scale emulation.
Due to that, large projects are expensive and mobile or energy projects or research is not recommended with EmuFog.
Additionally, its overhead is quite high, making it inefficient for quick prototyping and algorithm development.

% ----------------------------------
\subsection{Mockfog 2.0}\label{sec:Mockfog 2.0}
Mockfog 2.0 [\cite{sim-mockfog2}] is a widely adopted and well established tool in the simulation landscape and is a successor of the previous Mockfog (1.0) [\cite{sim-base-mockfog1}].
It is not a simulator like the previous mentioned, but an cloud-based emulator written in Node.js, which focuses on fog and edge computing for real application testing.
The emulator was first published 2021 and the development halted around June 2021.

Mockfog 2.0 presents a real infrastructure emulation in cloud environments to test fog applications under realistic conditions.
It features docker containerization and automated experiment orchestration while maintaining a real cloud-based emulation with runtime network manipulation.

Due to being a emulation, the resulting behavior is realistic and accurate. 
Additionally, it allows for dynamic,realistic and scalable testing scenarios and reduces manual effort.
With this it succeeds in its main goal of real application testing, but also is useful for validation of prototypes, algorithms and performance.
Additionally, it can be used for infrastructure capacity planning and industrial research making it quite adaptable.

Nevertheless, due to having a cloud infrastructure usage it has high cost and a complex setup.
It is not suitable for large-scale theoretical studies and cannot test theoretical algorithms easily.
Additionally, it has limited mobility support making it inefficient for some projects.

% ----------------------------------
\subsection{Fogify}\label{sec:Fogify}
Fogify [\cite{sim-fogify}] is a Python based emulator that focuses on fog/edge computing in a cloud-native container orchestration based network emulation.
It is designed to be realistic, reproducible and to server scalable fog/edge testbeds using containers.
First published in November 2020, Fogify shows a relatively active development with a modern docker and kubernetes based approach for linux networking.

Due to being realistic and reproducible fog/edge testbeds, it shines at testing real applications in such scenarios.
Furthermore, due to its container and kubernetes integration it supports declarative scenario description and therefore being relatively easy to configure and quite modern.

Sadly, it features no built-in energy modeling which makes it insufficient for energy-focused research unless the energy-consumption is instrumented externally.
Large-scale and time-accelerated scenarios also struggle with Fogify, as its hardware-limited scalability stands in the way.

% ----------------------------------
\subsection{iContinuum}\label{sec:iContinuum}
iContinuum [\cite{sim-icontinuum}] joins Fogify as a python based emulator that uses docker containerization and kubernetes to emulate linux networking.
Here, it is also designed to be realistic and reproducible, but other than the previous, focuses on cloud-to-edge, orchestration and reproducibility of large-scale experimentations. 

iContinuum succeeds in its goals by serving realistic and reproducible cloud-to-edge continuum testbeds while maintaining a multi-domain orchestration and declarative scenario description.
It is therefore suitable for orchestration research across the cloud-edge continuum, testing real applications in distributed scenarios and in network-based resource emulation.

However, just like its competitor, it is hardware-limited in its scalability and has no synthetic time like simulators in this field.
Additionally, it has no built-in energy modeling, making it not as suitable for large-scale, time-accelerated or energy-focused simulation.

% ----------------------------------
\subsection{FogNetSim++}\label{sec:FogNetSim++}
FogNetSim++ [\cite{sim-fognetsim++}] is relatively well known and established tool written in C++ and first published October 2018.
It is based on the OMNeT++\footnote{\url{https://omnetpp.org/}} and INET\footnote{\url{https://inet.omnetpp.org/}} Framework and focuses on network-centric fog environemnts with distributed fog systems.
The development halted as of the same month.

FogNetSim++ succeeds in advance network modeling with packet-level precision and with the built on proven OMNeT++ framework it shows extensive networking capabilties.
Furthermore, it present excellent scalabilities for large-scale network simulations and broad selection of debunnging and visualization tools.
Additionally, it also present deterministic and reproducible simulation results.
This supports network performance analysis and protocol development as well as large-scale network simulation with fog nodes and academic research that requires high network simulation accuracy.

However, due to being highly reliant on OMNeT++ and INET, further development and customization of the simulator require expertise and shows a steep learning curve and complex setup.
Adittionally, the documentation is relatively limited and due to the focus primarly laying on networking other components are being neglected.
This makes the simulator relatively inefficient for quick prototyping and real-time system simulation as well as energy- and security-focused studies.

% ----------------------------------
\subsection{FogTorch$\Pi$}\label{sec:FogTorchPi}
FogTorch$\Pi$ [\cite{sim-fogtorchpi}] is a well established probabilistic analysis tool in graph structure application deployment.
Written in Java in May 2017, FogTorch$\Pi$ focuses on fog computing, Quality of Service (QoS) aware deployment optimization as well as IoT application deployment.
With its probabilistic QoS-assurance and resource consumption estimation for eligible deployments of fog application with focus on deployment descision support, it serves a unique focus in the simulation landscape.
No visible development can be observed since January 2019.

It succeeds in clear separation between infrastructure and application modeling as well as cost-aware deployment optimization.
Therefore, it is best used for fog application deployment planning, QoS-aware deployment optimization, cost analysis for fog deployments and general academic research on deployment strategies in the fog computing field.

However, it features no runtime simulation capabilties and the deployment analysis is rather static with no dynamic reconfiguration or adaptation.
Furthermore, no ernergy or security modeling is present and its limited scalability makes it inefficient for energy or security based large-scaled projects.

% ----------------------------------
\subsection{EdgeAISim}\label{sec:EdgeAISim}
EdgeAISim [\cite{sim-edgeAIsim}] is a relatively new simulator, first published in October 2023, and focuses on the growing trend of artificial intelligence on the edge.
It features an extension to EdgeSimPy [\cite{sim-base-edgeSimpy}], which is written in Python, and focuses on resource management and energy optimization for artificial intelligence and machine learning workflows on the edge.

The integration of advanced AI models for intelligent resource management as well as the use of advanced artificial intelligence techniques like multi-armed bandit, Deep Q-Networks (DQN) and GNNs, makes it an 
efficient simulator in regards to scenarios of energy optimization studies, intelligent resource management and task scheduling algorithm development on the edge.

As EdgeAISim is a relatively small extension and has a very strict focus, it lacks in multiple other features that its competitors present.
Due to this, scenarios without artificial intelligence requirements don't reap any benefits from this simulator, as the workflow either hindered by additional workload or is simply 
delegated to EdgeSimPy.

\begin{figure}[H]
  \centering
  \begin{tabularx}{\textwidth}{l | c | c | X }
    \hline
    \textbf{Name} & \textbf{Language} & \textbf{Type} & \textbf{Focus} \\\hline
    EdgeCloudSim  & Java & Sim & Mobile Edge Computing, General Edge Computing\\\hline
    iFogSim2      & Java & Sim & IoT, Mobile Edge Computing, Microservices\\\hline
    YAFS          & Python & Sim & IoT, resource allocation, complex networks theory\\\hline
    EmuFog        & Kotlin & Emu & Large-scale fog infrastructure\\\hline
    Mockfog 2.0   & Node.js & Emu & Real application testing, Cloud-based emulation\\\hline
    Fogify        & Python & Emu & Container orchestration, Network emulation\\\hline
    iContinuum    & Python & Emu & Orchestration, Large-scale experimentation\\\hline
    FogNetSim++   & C++ & Sim & Realistic network-centric distributed systems\\\hline
    FogTorch$\Pi$ & Java & Sim & IoT application deployment, QoS-aware deployment optimization\\\hline
    EdgeAISim     & Python & Sim & AI/ML Edge Computing, Resource management, Energy optimization\\\hline
  \end{tabularx}
  \caption{Summary of representatives of the edge computing simulation landscape}
  \label{tab:overview-table-representatives}
\end{figure}
\todo{Do I need to add a footnote or something to describe what "Sim" and "Emu" is in type ?}

% ------------------------------------------
\section{Comparative Analysis}
In the following, we further dive into each aspect of the representatives and find similarities and differences.
To do that, we first introduce our analysis framework, which covers which aspects we observe, what value they bring to the simulation landscape and what the general structure for our comparison is.
After that we start with the comparison, covering each aspect and dive into further insights that come up during the process.
Additionally, we highlight some common patterns and findings as well as mention some gaps due to missing capabilities, limitations and emerging requirements.

% ----------------------------------
\subsection{Analysis Framework}
To systematically compare each representative with different architectures, foci and implementation approaches, we establish a foundation in form of a framework.
Given that our selected representatives range from simulators to emulators with varying specialized purposes, direct feature-to-feature comparison would be insufficient.
Instead, our framework considers both the specific goals of each representative and the influence of it in the edge computing simulation landscape.
A feature of a fog-edge emulator, may not be a great fit for a cloud-edge simulator, but still can have some insights and useful information regarding implementation or general design.

The framework encompasses six core dimensions that collectively address the complete software lifecycle from development, through deployment to its usage and assessment.
This holistic approach ensures our analysis captures not only what they can do, but also how well it serves researches and users across diverse edge computing scenarios.

\subsubsection{Architectural Dimensions}
The architectural foundation determines the flexibility, maintainability and ability to accurately represent edge computing environments.
It concerns itself with the design choices during the development of the simulator.
This can include the choice of the coverage scope, simulation paradigm, the general design philosophy, architecture patterns and integrations capabilities.

Which layer the simulator covers, is important to understand its purpose and capabilities. 
The coverage scope not only determines requirements for protocols and other features, but also different use cases and therefore the general focus.
It further can determine required modeling complexity, affects scalability requirements and shapes varied approaches during development and usage.
Furthermore, some capabilities, requirements and approaches can be essential for a layer in general.

The choice of the simulation paradigm ,on the other hand, determines whether simulators employ discrete-event simulation for network dynamics, 
continuous-time modeling for resource consumption, agent-based approaches for autonomous behavior or hybrid combinations that leverage multiple paradigms simultaneously.
As all these different paradigms, can have influence over simulation accuracy, time and resource usage, the selection should be not made hastely.

Hence, the general design philosophy is a criticial point, as it can not only determine the simulation paradigm but also can directly influence the focus of the simulator.
As we established, different foci doesn't mean that no insight can be gained for ther simulators. This is also true for the design philosphy.

Additionally, the choice of a modular or monoltihc architecture pattern, is a foundational choice, as modular designs are known to be more maintainable by separating concerns into independent components, and 
monolithc implementations are deemed to be compacter by integrating all functionality within unified frameworks.

This extends to the integration of external tools, real-world system and other simulation platforms through APIs, data exchange protocols and worklfow integration support.
A closed process can be difficult to work with, as dynamic changes, collecting metrics and other processes that could be deemed useful from the outside are blocked off.
Nonetheless, they can be deemed secure, as no external tool can interfere with a running scenario and distort results.
On the other side, a open process could be insecure but easy to work with.
Additionally, blocking the important tools but allowing non-essential tools in, could be deemed just as insufficient and risky in terms of useability and security.
How much integration should be allowed and what integrations are necessary, is another aspect of the architectural design process.

\subsubsection{Functional Capabilities}
Functional capabilities encompass the breadth and depth of the edge computing scenarios each simulator can represent.
This does include general functionalities as well as focus-based capabilities, which needs to be weighted.

The general functionalities encompasses for example network modeling, device and infrastructure modeling and application and worload modeling as well as fault tolerance and reliability modeling and security and privacy concerns.

Network modeling assesses support for diverse network types, protocol implementations and realistic network conditions including variable delays, bandwidth constraint and congestion-aware behavior.
Additionally, simulated topologies and other feature can have impact in the network modeling as well, making it a core point in the simulator of choice.

Device and infrastructure modeling examines the range of supported device types from resource-constrained sensors to powerful edge servers, including resource modeling, heterogeneity support for diverse device capabilities and realistic scaling bahavior that reflects hardware constraints and performance characteristics.
The degree in which these device needs to be models are in correlation of the level of detail the simulator wants to accomplished and the focus.

Application and workload modeling investigates support for different application architectures, task dependency patterns and data flow models.
This includes evaluation of service migration capabilities, workload generation methods and QoS requirement modeling for latency, throughput and reliability constraints.

This gets extended by modeling fault tolerance and checking for reliability of the simulated devices and networks.
If the network modeling concerns itself with the aspects of variable delays, fault tolerance concerns itself with the case of failing nodes and devices that would maybe cause these delays.
By modeling fault tolerance, the simulator can check if the scenario is reliable in cases where devices disconnect. 

Furthermore, security and privacy of the simulator as well as the application are important for personal use as well as developing security-aware applications.
These points can be further extended by focus-based capabilities, as every type of focus can have qualifing capabilities for the edge computing landscape.
For example, if the focus lies on mobile devices, mobility modeling is necessary to model different delay and different data generation based on movement and distance to other nodes.
Energy consumption and sustainability can also be capabilities important for the simulator that need to be observed and weighted based on their respective influence in the edge computing simulation landscape.

\subsubsection{Performance and Scalability}
Performance characteristics directly impact practical utility for large-scale edge computing studies.
A simulator that can't be scaled or performs badly in realistic deployment requirements, can be deemed insufficient.
As scalability is a core aspect of the edge, it is a critical aspect that needs to be analysed for each simulation.

Computational efficiency measures simulation execution speed relative to scenario complexity, memory usage patterns and effectiveness of optimization features including caching, checkpointing and incremental simulation capabilities.

Scalability limits determine practical boundaries for scenario complexity, including maximum supportable network nodes, concurrent applications and realistic scenario sizes before performance degrades unacceptably.
This assessment examines parallelization support through multi-threading, distributed processing or GPU acceleration and evaluates how performance scales with increasing scenario complexity.

Resource requirements document hardware dependencies, platform support across operating systems and scaling relationships between simulation complexity and computational demands.
The evaluation includes assessment of memory efficiency, CPU utilization patterns and any spezialized hardware requirements that might limit accessibility or deployment flexibility.

\subsubsection{Usability}
Usability factors significantly influence simulator adoption and research productivity.

An evaluation of the setup and deployment procress asseses installation complexity, dependency management and documentation quality as well as community support avalability.
This includes examination of platform compatibility, deployment options and the overall barrier to entry for new users.

Programming interface analysis compares configuration methods from graphical interfaces to prorgammic APIs, evaluating the balance btween ease of use and flexibility.
The assessment considers API design quality, example scenario availability and the steepness of the learning curve required for productive use across different users expertise levels.
This does not only include the pure usage of said simulator but also the further development.
Furthermore, it also observes the strictness of the simulator, as a simulator which can only be used for one specific scenario may not be suited in general.

Research workflow integration examines support for experimental design including scenario management, parameter sweep capabilities, reproducibility mechanisms through seed control and deterministic execution and statistical analysis features.
Effective simulators should provide data export capabilities, visualization support and integration with external analysis tools to support rigourous experimental methodologies and interpretation of the results in general.

\subsubsection{Extensibility and Customization}
Extensibility determines a simulator's ability to evolve with changing research needs and support novel edge computing concepts.
This ensures that the simulator grows with the changing simulation landscape, adapt modern approaches and can be customized for a variety of scenarios and use cases.
Hence, this aspect is highly dependent on other factors such as the architecture pattern but can also be achieved and influenced by other internal as well as external features.

Plugin architecture is a common way of adding new functionality without modifiying core code.
To assess this architecture, the availability of well-defined extension points, plugin management systems and the ease of integrationg custom components need to observed.

Programming extensibility evaluates API completeness and choice of programming language for custom development, scripting support for automation and the flexibility of extending exisiting models or creating entirely new behavioral representations.
This includes assessment of inheritance mechanisms, interface design and the complexity required for implementing custom device types, protocols or application models.

Data and metric extensibility investigates capabilities for custom metric definitions, support for novel data patterns, integration with real-world datasets and mechanisms for extending output analysis capabilities.
Robust extensibility should enable researchers to adapt simulators for emerging edge computing paradigms without requiring dfundamental architectural chanegs.

\subsubsection{Validation and Evaluation}
Validation capabilities ensure simulation credibility and enable meaningful research conclusion.
The accuracy of the simulators results is important, as inaccurate results defeat the whole purpose of the process as a whole.

Accuracy and validation asssesment examines built-in verification methods, calibration requirements against real-world data and documented accuracy claims with associated error bounds or precision levelvs.

Benchmarking and comparison evlauates availability of standard benchmark scenarios, reference implementationsfor comparative analysis and built-in metrics that enable fair evlauation across different approaches.
The assessment considers whether simulators provide validated baseline scenarios and support for reproductin published research results for comparison, review and transparency of the results.

Metrics and analysis support examines the comprehensivesness of built-in measurement capabilities, configurability of ourput generation and support of custom metric definition.
Effective evaluation support should, as mentioned in previous aspects, include statiscal analysis features, data export capabilities in standard formats and visualization tools that facilitate both real-time monitoring and post processing analysis of simulation results. 

% ----------------------------------
\subsection{Analysis \& Results}
\subsubsection{Architectural Dimensions Comparison}

\subsubsection{Functional Capabilities Comparison}

\subsubsection{Performance and Scalability Comparison}

\subsubsection{Usability and User Experience Comparsion}

\subsubsection{Extensibility and Customization Comparison}

\subsubsection{Validation and Evaluation Support Comparison}
% ----------------------------------
\subsection{Key Findings \& Gap Analysis}
\todo{Common patterns, performance leaders, comprehensive solutions, specialized tools}
\todo{Missing capabilities, limited coverage area, scalability limitations, validation weaknesses, integration challenges, emerging requirements}