\chapter{Introduction}
Edge computing has emerged as a transformative paradigm that extends computational capabilities from centralized cloud infrastructure to the network's periphery, 
reducing latency, minimizing bandwidth usage and enabling applications that require immediate response times [\cite{7488250}].
The development has thereby led edge computing as a complement for cloud computing [\cite{ASHOURI2021100346}]. 
With IoT devices projected to grow exponentially [\cite{7488250}, \cite{10258346}], the demand for real-time, low-latency applications, has led organizations to 
increasingly adopt edge computing architectures to support IoT deployments, autonomous systems, and real-time analytics.  
Consequently, robust simulation environments have become increasingly critical for system design, performance evaluation, and deployment planning.

The complexity and heterogeneity inherent in edge computing environments present significant challenges for researchers and developers seeking to evaluate system performance, 
optimize resource allocation, and validate architectural decisions before costly real-world deployments. 
However, deploying and testing edge computing solutions in real-world scenarios presents substantial obstacles, including high costs, time commitments, and physical constraints 
that make them highly impractical for research and development purposes [\cite{ASHOURI2021100346}, \cite{7488250}]. 

Hence, numerous edge computing simulators have been developed within the research community, each offering different foci, distinct capabilities, architectural approaches, and evaluation metrics. 
These simulators serve as essential tools for analyzing resource allocations, algorithms, configurations, and deployment strategies before committing to physical implementations.

Despite the rapid growth of the edge computing simulation landscape, existing simulators often present different aspects and potentially incomplete or biased simulation environments [\cite{ASHOURI2021100346}]. 
Many simulators focus on specific aspects of edge computing while potentially overlooking other critical factors that influence real-world performance.
Additionally, as research progresses in new technologies that become available and standardized like machine learning, containerized applications and orchestrations platforms like for example Kubernetes, the need to extend 
these technologies to edge environments have become critical.
Yet there remains a gap in understanding which aspects are essential or only recommended in the simulation landscape.

The absence of standardized evaluation criteria and comprehensive comparative analyses leaves researchers and developers without clear guidance on which simulators possess the necessary 
characteristics to accurately model edge computing scenarios. 
This gap in knowledge not only hinders research reproducibility but also potentially leads to suboptimal design decisions based on insufficient simulation foundations.

This is the primary objective of this thesis, in which we establish a framework for evaluating edge computing simulators and guide researches and developers alike in creating new simulators while additionally 
demonstrating its practical application through the enhancement of an existing one.
This work addresses the fundamental question of what essential accounts for requirements and characteristics that define a comprehensive and effective edge computing simulator.

To answer this question, this thesis begins with the exploration of necessary foundations in Chapter 2.
Chapter 3 examines key similarities and differences among current state-of-the-art edge computing simulators across multiple dimensions, providing a comprehensive analysis of the simulation landscape.
Through this analysis, Ecoscape is evaluated alongside established simulators to assess its positioning within the current state-of-the-art.
Based on patterns identified in the comparison, Chapter 4 presents a requirements catalogue that formalizes the essential chracteristics and capabilities of effective edge computing simulators.
Chapter 5 addresses a gap identified during the analysis in Ecoscape through development and implementation of a LLM deployment use case that demonstrates the simulator's capabilities.
This use-case gets further established by depicting experiments and their evaluation in Chapter 6.
Finally, Chapter 7 concludes this thesis with reflections on future work.